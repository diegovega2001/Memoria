# CompCars - AnÃ¡lisis de VehÃ­culos con Deep Learning

[![Python 3.12.6](https://img.shields.io/badge/python-3.12.6-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.2.2-red.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## DescripciÃ³n

Proyecto de investigaciÃ³n para clasificaciÃ³n de vehÃ­culos utilizando el dataset **CompCars** con tÃ©cnicas de deep learning y visiÃ³n computacional. Implementa modelos de visiÃ³n multi-vista, anÃ¡lisis de embeddings, clustering y pipelines reproducibles para fine-tuning.

### Objetivos Principales

- **Fine-tuning** de modelos pre-entrenados (ResNet, etc.)
- **AnÃ¡lisis de embeddings** antes y despuÃ©s del fine-tuning  
- **Clustering y visualizaciÃ³n** de representaciones aprendidas
- **Soporte multi-vista** (front/rear) de vehÃ­culos
- **Pipelines reproducibles** con configuraciÃ³n JSON

## Arquitectura del Proyecto

```
CompCars/
â”œâ”€â”€ src/                          # CÃ³digo fuente principal
â”‚   â”œâ”€â”€ config/                   # Configuraciones
â”‚   â”‚   â”œâ”€â”€ TransformConfig.py   # Transformaciones de imÃ¡genes
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ data/                     # Procesamiento de datos      
â”‚   â”‚   â”œâ”€â”€ DataFrameMaker.py    # GeneraciÃ³n de dataset CSV
â”‚   â”‚   â”œâ”€â”€ MyDataset.py         # Dataset personalizado PyTorch
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ models/                   # Modelos de ML
â”‚   â”‚   â”œâ”€â”€ Criterions.py        # Criterions para metric learning
â”‚   â”‚   â”œâ”€â”€ MyVisionModel.py     # Modelo multi-vista
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ pipeline/                 # Pipelines de experimentaciÃ³n
â”‚   â”‚   â”œâ”€â”€ FineTuningPipeline.py # Pipeline de entrenamiento
â”‚   â”‚   â”œâ”€â”€ EmbeddingsPipeline.py # Pipeline de anÃ¡lisis
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â””â”€â”€ utils/                    # Utilidades
â”‚       â”œâ”€â”€ ClusteringAnalyzer.py # AnÃ¡lisis de clustering
â”‚       â”œâ”€â”€ DimensionalityReducer.py # ReducciÃ³n dimensional
â”‚       â”œâ”€â”€ ClusterVisualizer.py  # VisualizaciÃ³n
â”‚       â”œâ”€â”€ JsonUtils.py         # Utilidades JSON
â”‚       â””â”€â”€ __init__.py
â”œâ”€â”€ dataset/                      # Dataset CompCars
â”‚   â”œâ”€â”€ image/                   # ImÃ¡genes por categorÃ­as
â”‚   â””â”€â”€ label/                   # Etiquetas y metadatos
â”œâ”€â”€ experiments/                  # Configuraciones experimentales
â”œâ”€â”€ results/                      # Resultados y modelos guardados
â”œâ”€â”€ requirements.txt              # Dependencias completas
â”œâ”€â”€ requirements-dev.txt          # Dependencias esenciales
â”œâ”€â”€ dataset.csv                   # Dataset creado por DataFrameMaker.py
â”œâ”€â”€ config.json                   # Configs de finetuning y estudio de embeddings
â””â”€â”€ README.md                    # Este archivo
```

## InstalaciÃ³n y ConfiguraciÃ³n

### 1. Prerrequisitos

- Python 3.12.6+
- CUDA compatible GPU (recomendado)
- Git LFS para archivos grandes del dataset

### 2. ClonaciÃ³n del repositorio

```bash
git clone https://github.com/diegovega2001/Memoria.git
cd Memoria/CompCars
```

### 3. Entorno virtual

```bash
# Crear entorno virtual
python -m venv .venv

# Activar entorno (macOS/Linux)
source .venv/bin/activate

# Activar entorno (Windows)
.venv\\Scripts\\activate
```

### 4. InstalaciÃ³n de dependencias

```bash
# InstalaciÃ³n completa
pip install -r requirements.txt

# O instalaciÃ³n solo dependencias esenciales
pip install -r requirements-dev.txt
```

### 5. InstalaciÃ³n del proyecto

```bash
pip install -e .
```

## ðŸ’¡ Uso RÃ¡pido

### Importaciones bÃ¡sicas

```python
from src import CarDataset, MultiViewVisionModel, FineTuningPipeline
from src.config import TransformConfig
from src.utils import ClusteringAnalyzer
```

### 1. Crear dataset

```python
from src.data import create_car_dataset
from src.config import create_standard_transform

# Configurar transformaciones
transform = create_standard_transform(
    resize=(224, 224),
    normalize=True,
    augment=False
)

# Crear dataset
dataset = create_car_dataset(
    csv_path="dataset.csv",
    root_dir="dataset/",
    transform=transform,
    views=['front', 'rear'],
    model_type='vision'
)
```

### 2. Fine-tuning de modelo

```python
from src.pipeline import create_finetuning_pipeline

# Crear pipeline
pipeline = create_finetuning_pipeline(
    model_name="resnet50",
    dataset=dataset,
    batch_size=32,
    learning_rate=1e-4,
    epochs=10
)

# Ejecutar fine-tuning
pipeline.run_finetuning()
```

### 3. AnÃ¡lisis de embeddings

```python
from src.pipeline import create_embeddings_pipeline

# Pipeline de anÃ¡lisis
embeddings_pipeline = create_embeddings_pipeline(
    model_path="results/model.pth",
    dataset=dataset
)

# Extraer y analizar embeddings
embeddings_pipeline.extract_embeddings()
embeddings_pipeline.analyze_embeddings()
```

## Flujo de Trabajo TÃ­pico

```python
# 1. Preparar datos
dataset = create_car_dataset(...)

# 2. Extraer embeddings baseline
pipeline = create_finetuning_pipeline(...)
pipeline.extract_baseline_embeddings()

# 3. Fine-tuning
pipeline.run_finetuning()

# 4. Extraer embeddings fine-tuned
pipeline.extract_finetuned_embeddings()

# 5. AnÃ¡lisis comparativo
embeddings_pipeline = create_embeddings_pipeline(...)
embeddings_pipeline.analyze_embeddings()
```

## ConfiguraciÃ³n

### TransformConfig

```python
from src.config import TransformConfig

config = TransformConfig(
    grayscale=False,           # Mantener colores
    resize=(224, 224),         # TamaÃ±o ImageNet
    normalize=True,            # NormalizaciÃ³n ImageNet
    use_bbox=True             # Usar bounding boxes
)
```

### ConfiguraciÃ³n de clustering

```python
from src.utils import ClusteringAnalyzer

analyzer = ClusteringAnalyzer(
    algorithms=['dbscan', 'hdbscan', 'optics'],
    optimize_hyperparameters=True,
    n_jobs=-1
)
```

## CaracterÃ­sticas Principales

### **Reproducibilidad**
- Seeds controladas en todos los componentes
- Configuraciones JSON persistentes
- Logging detallado de experimentos

### **Modularidad**
- Pipelines independientes y reutilizables
- Componentes intercambiables
- APIs consistentes

### **AnÃ¡lisis Completo**
- Clustering con mÃºltiples algoritmos
- ReducciÃ³n dimensional (PCA, t-SNE, UMAP)
- MÃ©tricas de evaluaciÃ³n detalladas

### **Multi-Vista**
- Soporte nativo para mÃºltiples viewpoints
- FusiÃ³n de caracterÃ­sticas multi-vista
- AnÃ¡lisis comparativo por vista

### **Persistencia**
- Guardado automÃ¡tico de resultados
- Versionado de modelos y embeddings
- Visualizaciones exportables

## Dataset CompCars

El proyecto utiliza el dataset **CompCars** que contiene:

- **163 marcas de vehÃ­culos**
- **1,716 modelos diferentes**
- **~214,000 imÃ¡genes**
- **MÃºltiples viewpoints** (front, rear, side)
- **Bounding boxes** para cada vehÃ­culo
- **Metadatos** (aÃ±o, tipo, modelo)

### Estructura del CSV generado:

```csv
image_name,image_path,released_year,viewpoint,bbox,make,model,type
826a5fd082682c,dataset/image/135/947/unknown/826a5fd082682c.jpg,unknown,rear,"[96.0, 53.0, 817.0, 596.0]",Saab,SAAB 9X,Unknown
```

## Testing

```bash
# Ejecutar tests bÃ¡sicos
python -m pytest tests/

# Tests con coverage
python -m pytest tests/ --cov=src --cov-report=html
```

## Logging

El proyecto incluye logging configurado:

```python
import logging
logging.basicConfig(level=logging.INFO)

# Los mensajes aparecerÃ¡n automÃ¡ticamente
```

## Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver `LICENSE` para mÃ¡s detalles.

## Autor

**Diego Vega** - [diegovega2001](https://github.com/diegovega2001)